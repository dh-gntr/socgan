https://colab.research.google.com/drive/1anNEQfRpkAhqQuRSg608SVh_lbpQiEX1#scrollTo=T3wnT0edU8Xb

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

input_size = 784
hidden_size = 200
num_classes = 10
num_epochs = 2
batch_size = 100
lr = 0.001

train_dataset = torchvision.datasets.MNIST(root = "./sample_data/", train = True, download = True, transform = transforms.ToTensor())

test_dataset = torchvision.datasets.MNIST(root = "./sample_data/", train=False, transform = transforms.ToTensor())

train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = 100, shuffle = True)
test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = 100, shuffle=False)

examples = iter(train_loader)
samples , labels = next(examples)

#plt.imshow(samples[0][0])

class NeuralNet(nn.Module):
  def __init__(self,input_size, hidden_size, num_classes):
    super(NeuralNet, self).__init__()

    self.l1 = nn.Linear(input_size, hidden_size)
    self.relu = nn.ReLU()
    self.l2 = nn.Linear(hidden_size, num_classes)

  def forward(self,x):
    out = self.l1(x)
    out = self.relu(out)
    out = self.l2(out)
    return out

model = NeuralNet(input_size, hidden_size, num_classes)

criteria = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = lr)

for epoch in range(num_epochs):
  for i, (images,labels) in enumerate(train_loader):
    images = images.reshape(-1,784)
    output = model(images)
    loss = criteria(output,labels)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

with torch.no_grad():
  n_correct = 0
  n_samples = 0
  for (images,labels) in test_loader:
    images = images.reshape(-1, 784)
    output = model(images)
    _,predicted = torch.max(output,1)
    n_samples+=labels.shape[0]
    n_correct+= ((predicted==labels).sum().item())

print(f'accuracy={(n_correct/n_samples):.2f}')
